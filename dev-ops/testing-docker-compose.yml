version: '3'
services:
  zookeeper:
    image: 'confluentinc/cp-zookeeper:7.3.0'
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOOKEEPER_CLIENT_PORT=2181
    networks:
      - elevate_net
    logging:
      driver: none
  kafka:
    image: 'confluentinc/cp-kafka:7.3.0'
    ports:
      - '9092:9092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
    networks:
      - elevate_net
    logging:
      driver: none

  redis:
    image: 'redis:7.0.0'
    restart: 'always'
    expose:
      - '6379'
    networks:
      - elevate_net
    logging:
      driver: none

  postgres:
    image: 'postgres:latest'
    ports:
      - '5432:5432'
    environment:
      - POSTGRES_DB=integration_test_scp
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    networks:
      - elevate_net
    logging:
      driver: none
  
  schedular:
    image: shikshalokamqa/elevate-scheduler:2.6.1
    ports:
      - '4000:4000'
    command: ['nodemon', 'app.js']
    environment:
      - KAFKA_URL=kafka:9092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - kafka
      - redis
    networks:
      - elevate_net
    env_file:
      - integration_test.scheduler.env

  user:
    build: '../../user/'
    ports:
      - '5001:5001'
    volumes:
      - ../../user/src/:/var/src
    command: >
      bash -c "echo 'Waiting for PostgreSQL to accept connections...' &&
        until timeout 1 bash -c '</dev/tcp/postgres/5432' >/dev/null 2>&1; do
            echo 'Waiting for PostgreSQL to be ready...'
            sleep 1
        done &&
        echo 'Database is ready.' &&
        if ! psql -U postgres -h postgres -lqt | cut -d \| -f 1 | grep -qw integration_test_user; then
            npm run db:init && npm run db:seed:all
        else
            echo 'Database already exists. Skipping initialization and seeding.'
            exit 0  # Exit successfully to prevent the container from stopping
        fi &&
        (echo 'Running User' && nodemon app.js &) &&
        (/bin/bash -c 'cd scripts && echo Running user service scripts && node insertDefaultOrg.js && node viewsScript.js && node -r module-alias/register uploadSampleCSV.js') &&
        tail -f /dev/null"
    depends_on:
      - kafka
      - redis
      - schedular
      - postgres
    environment:
      - DEV_DATABASE_URL=postgres://postgres:postgres@postgres:5432/integration_test_user
      - KAFKA_URL=kafka:9092
      - REDIS_HOST=redis://redis:6379
    networks:
      - elevate_net
    env_file:
      - integration_test.user.env

  survey-project-creation-service:
    build: '../../survey-project-creation-service/'
    ports:
      - '6001:6001'
    command: >
      bash -c "

        echo 'Waiting for User to accept connections...'
        until timeout 1 bash -c '</dev/tcp/user/5001' >/dev/null 2>&1; do
            echo 'Waiting for User to be ready...'
            sleep 1
        done &&
        echo 'User Service is ready.'

        npm run db:init &&
        (echo 'Running SCP' && nodemon app.js &) &&
        (/bin/bash -c 'cd scripts && echo Running scp service scripts && node -r module-alias/register uploadCertificateBaseTemplate.js') &&
        tail -f /dev/null"
    volumes:
      - ../../survey-project-creation-service/src/:/var/src
    environment:
      - DEV_DATABASE_URL=postgres://postgres:postgres@postgres:5432/integration_test_scp
      - KAFKA_URL=kafka:9092
      - REDIS_HOST=redis://redis:6379
    depends_on:
      - postgres
      - kafka
      - redis
      - user
    networks:
      - elevate_net
    env_file:
      - integration_test.self_creation_portal.env

networks:
  elevate_net:
    external: false

volumes:
  zookeeper-data:
  kafka-data: